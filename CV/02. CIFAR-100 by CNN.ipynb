{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用卷积神经网络解决CFIAR-100\n",
    "\n",
    "\n",
    "> 实际上使用的是VGG-13，但是效果不好；100分类问题训练5轮后accuracy仅为20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需模块\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets,layers,optimizers,metrics,losses,Sequential\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据集\n",
    "(x,y),(x_test,y_test) = datasets.cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "'''\n",
    "1. 归一化\n",
    "2. 类型转换\n",
    "3. 整理成tf.Data对象\n",
    "'''\n",
    "batch_size = 128\n",
    "\n",
    "def preprocess(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float32)/255.\n",
    "    y = tf.cast(y,dtype=tf.int32)\n",
    "    y = tf.squeeze(y,axis=0)\n",
    "    return x,y\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "train_data = db.map(preprocess).shuffle(10000).batch(batch_size)\n",
    "\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "test_data = db_test.map(preprocess).shuffle(10000).batch(batch_size) # test数据可以不用打乱\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 32, 3)\n",
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "# 展示\n",
    "sample = next(iter(train_data))\n",
    "print(sample[0].shape)\n",
    "print(sample[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            multiple                  1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "=================================================================\n",
      "Total params: 3,910,784\n",
      "Trainable params: 3,910,784\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 搭建卷积层、全链接层\n",
    "conv_net = Sequential([\n",
    "    layers.Conv2D(64,3,padding = 'same',activation = tf.nn.relu),\n",
    "    layers.MaxPool2D(strides=2,padding = 'same'),\n",
    "    \n",
    "    layers.Conv2D(128,3,padding = 'same',activation = tf.nn.relu),\n",
    "    layers.MaxPool2D(strides=2,padding = 'same'),\n",
    "    \n",
    "    layers.Conv2D(256,3,padding = 'same',activation = tf.nn.relu),\n",
    "    layers.MaxPool2D(strides=2,padding = 'same'),\n",
    "    \n",
    "    layers.Conv2D(512,3,padding = 'same',activation = tf.nn.relu),\n",
    "    layers.MaxPool2D(strides=2,padding = 'same'),\n",
    "    \n",
    "    layers.Conv2D(512,3,padding = 'same',activation = tf.nn.relu),\n",
    "    layers.MaxPool2D(strides=2,padding = 'same'),\n",
    "    \n",
    "    layers.Flatten()\n",
    "])\n",
    "conv_net.build(input_shape = [None,32,32,3])\n",
    "conv_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 512)\n"
     ]
    }
   ],
   "source": [
    "# 测试卷积\n",
    "sample_data = tf.random.normal([10,32,32,3])\n",
    "out = conv_net(sample_data)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  25700     \n",
      "=================================================================\n",
      "Total params: 419,684\n",
      "Trainable params: 419,684\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc_net = Sequential([\n",
    "    layers.Dense(512,activation=tf.nn.relu),\n",
    "    layers.Dense(256,activation=tf.nn.relu),\n",
    "    layers.Dense(100,activation=tf.nn.sigmoid),\n",
    "])\n",
    "fc_net.build(input_shape = [None,512])\n",
    "fc_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100)\n"
     ]
    }
   ],
   "source": [
    "fc_test = tf.random.normal([10,512])\n",
    "y_fc_test = fc_net(fc_test)\n",
    "print(y_fc_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0925 22:31:17.166961 16572 deprecation.py:323] From E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 : loss = 4.604790210723877 208.34791497451806 pic/s \n",
      "step 50 : loss = 4.594887733459473 2137.679949230101 pic/s \n",
      "step 100 : loss = 4.4716973304748535 2333.509561920041 pic/s \n",
      "step 150 : loss = 4.364353656768799 2140.3966422527674 pic/s \n",
      "step 200 : loss = 4.307084560394287 2292.3457143880514 pic/s \n",
      "step 250 : loss = 4.247390270233154 2212.8483507364635 pic/s \n",
      "step 300 : loss = 4.239736557006836 2212.7718424783043 pic/s \n",
      "step 350 : loss = 3.9944348335266113 2421.4907302307984 pic/s \n"
     ]
    }
   ],
   "source": [
    "# 搭建训练过程（GradTape实现）\n",
    "max_iter = 5\n",
    "optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "for iter_step in range(max_iter):\n",
    "    for i,(ix,iy) in enumerate(train_data):\n",
    "        begin_time = datetime.datetime.now()\n",
    "        with tf.GradientTape() as tape:\n",
    "            out_conv = conv_net(ix)\n",
    "            out_fc = fc_net(out_conv)\n",
    "            iy_onehot = tf.one_hot(iy,depth=100)\n",
    "            ce = losses.categorical_crossentropy(iy_onehot,out_fc)\n",
    "            loss = tf.reduce_mean(ce)\n",
    "        grads = tape.gradient(loss,conv_net.trainable_variables + fc_net.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads,conv_net.trainable_variables + fc_net.trainable_variables))\n",
    "        \n",
    "        end_time = datetime.datetime.now()\n",
    "        \n",
    "        \n",
    "        if i%50==0:\n",
    "            print('step {0} : loss = {1} {2} pic/s '.format(i,float(loss),batch_size/(end_time-begin_time).total_seconds()))\n",
    "\n",
    "#   vaildation\n",
    "    tot = 0\n",
    "    for x_t,y_t in test_data:\n",
    "        out_conv = conv_net(x_t)\n",
    "        prob = fc_net(out_conv)\n",
    "        predict = tf.cast(tf.argmax(prob,axis = 1),dtype=tf.int32) \n",
    "        corr = tf.equal(y_t,predict)\n",
    "        corr = tf.reduce_sum(tf.cast(corr,dtype = tf.int32))\n",
    "        tot += corr\n",
    "    print('Accuracy = {0}  --> ITER {1}'.format(int(tot)/10000.,iter_step))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
