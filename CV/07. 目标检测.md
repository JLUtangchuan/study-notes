# 目标检测算法

## 一、参考资料
### 视频
- [目标检测算法 慕课网](https://www.bilibili.com/video/av70977633) 非常全，包含通用目标检测和人脸检测的许多经典论文
- [旷视科技资深研究员俞刚-Beyond RetinaNet & Mask R-CNN](https://www.bilibili.com/video/av29340771)

### 文章

- [SSD](https://www.cnblogs.com/cmai/p/10076050.html)
- [L1 L2 smooth L1 loss总结](https://blog.csdn.net/yang_daxia/article/details/91360606)

## 二、方法分类
### 传统算法
  - VJ（Haar + Adaboost + SVM）
  - HOG & SVM
  - DPM
### 深度学习方法
  - #### two stage
    - R-CNN
      - selective search + *resize* + deep feature extract + *svm*
    - SPP Net
      - Kaiming He等人的工作（Res Net的四个作者）
      - 针对候选框size不一致提出一种多尺度金字塔池化，做全局3x3,5x5的池化,flatten,concat
      - 将推荐区域对应的特征图而不是原始图像送入网络中进行reg & cls,避免卷积的重复计算
      - ![](img/spp.png)
    - fast RCNN
      - RBG（MS）
      - ROI Pooling 单一尺度全局池化
      - 借鉴SPP Net使用特征图进行后边的分类与refine
      - 缺点：仍然需要Selective search
    - faster RCNN
      - HKM，RBG，SJ
      - RPN 全卷积网络，用于输出推荐区域（前景背景+bbox），最后一层特征图每个点有若干个anchor，每个anchor的默认size和shape都不一样
      - 训练时anchor与某个gt的iou大于某个threshold则为pos，小于某个threshold视为neg sample
      - 在训练分类、回归阶段的网络时，注意正负样本的比例
    - FPN
      - 横向连接，多尺度检测，Element-wise ADD
      - two-stage做法，在区域推荐生成部分提出新的特征金字塔模式，在ROI池化部分使用更适合于精细任务的ROI Align
      - 可以用于做实例分割
    - Mask R-CNN
      - FPN的基础上进行，在ROI Align后面多接了一个FCN（能够上采样）
      - 实例分割（检测+分割）
      - ROI Align
  - #### one stage
    - YOLO
        > 单一尺度检测，在小的特征图后面接全连接层，相当于增大感受野
        >
        > 作者认为，正是这种全局的推理，使得FP相比faster rcnn等只利用局部信息的RPN的方法会更少
        - v1
        
          > SxS个预测点，每个点预测两个框（置信度+xyhw）、预测这个点对应的类别
          >
          > 预测的框表示中心在这个点对应的区域的物体的估计框
          >
          > 缺点：
          >
          > ​	小物体检测
	      >
	      > ​	密集物体检测
	    
	      <img src=".\img\yolo.png" style="zoom:50%;" />
        
        |Paper|Year|Description|
        |:---:|:--:|:---------:|
        |You Only Look Once: Unified, Real-Time Object Detection|2015 rbg FAIR|v1|
        |||v2|
        |||yolo 9000|
        |||v3|
        
    - SSD
      
        - 2016 ECCV 多尺度检测 
    	
    	![](E:\Study Files\学习\唐川的人工智能笔记\代码与实验\CV\img\SSD.png)
    	
    	- anchor 数量统计
        
          <img src=".\img\ssd-anchor" alt="image-20200126234101206" style="zoom:50%;" />
        
        - **损失函数**
        
          - total loss
        
            > 分为定位损失和分类损失，N表示正负样本数量和
        
            <img src=".\img\ssd-totalloss.png" style="zoom:33%;" />
        
            - conf loss
        
              > softmax loss，使得输出的结果更像一个概率值；而且softmax相对于“hardmax”使得高概率值更高、低的更低
        
              <img src=".\img\ssd-confloss.png" style="zoom:33%;" />
        
            - locate loss
        
              > 计算所有正例的定位Smooth L1损失
          >
              > $\hat{g}$表示相对default box的相对偏移量，$d$表示default box的量，$g$表示GT真实的位置；W、H需要取对数使得值域可以为负（因为$l^h$可能为负）
        
          ​    
          
          ​    
          
            <img src="E:\Study Files\学习\唐川的人工智能笔记\代码与实验\CV\img\ssd-locloss.png" style="zoom:33%;" />
        
        - **正负样本构造**
        
          > **设计准则**：每个GT都要对应至少一个anchor，但每个anchor至多对应一个GT
          >
          > ​	先构造正样本，再根据正负样本比例和难样本挖掘的策略选择负样本；
          >
          > ​	正样本
          >
          > 		- 对于每一个GT，找最大IOU的default box放入正样本集合
          > 		- 选择所有default box与GT的 IOU > 0.5 
          > 
          >​	负样本
          > 
          >```
          > 	- 可以是小于一定阈值的
          > 	- 正负样本比例 1:3 使得模型更快、更稳定收敛
          > ```
          > 
          >
          > 
          >**难例挖掘**
          > 
          >```
          > 	- 根据当前模型的到的loss，选择高loss值的正负样本作为难例
          > ```
          > 
          >
        
    - Retina Net
  - #### anchor free
    - Corner Net
    - Center Net
    - Dense Box
  - #### Cascade
## 三、backbone
> 整个网络骨架发展的形式，由简单到复杂再到简单，AutoML探索定制化的网络结构
> 
> 复杂：
> 
>   1.网络层数更深 VGG & ResNet
> 
>   2.网络宽度加大 GoogLe Net Inception
> 
> 更轻量化的网络 Mobile Net & Shuffle Net

---

## 四、改进方向





### 模型结构探索

#### 图像金字塔 & 特征金字塔（FPN SSD）
> 传统的检测算法为了能检测不同尺寸的物体，通常采用滑窗加图像金字塔的方法；**SSD**提出在不同特征图上进行检测，使得小物体能在高分辨率的特征图上进行检测，大物体能在高语义信息的特征图上进行检测


> **FPN**总结了四种不同的图像/特征金字塔设计，其推崇的特征金字塔结构如图，高语义信息的特征图进行上采样（双线性插值）并与低语义信息高分辨率的特征图进行特征融合（add），并且在每一层上进行多尺度的检测。并且相比SSD，FPN网络利用了前面层的特征图

<img src="img/FPN.png" width="300px">


#### Convolution
- 空洞卷积

#### pooling

- ROI pooling
- ROI Align

#### Regularization

#### anchor free & anchor based


### 训练策略探索
#### 数据不平衡

#### 数据增强 & 难样本挖掘 & 正负样本
- Training Region-based Object Detectors with Online Hard Example Mining（OHEM）

#### loss
- cls
  - focal loss
  - softmax loss
  
- bbox reg
  
  <img src=".\img\smoothloss.svg" style="zoom:80%;" />
  
  | loss                  | 公式 | 优点                                          | 缺点                              |
  | --------------------- | ---- | --------------------------------------------- | --------------------------------- |
  | L1(最小绝对值偏差)    |      | 鲁棒                                          | 不稳定，可能多个解 难收敛         |
  | L2（最小平方误差LSE） |      | 凸优化，总是一个解                            | 不鲁棒(对于异常值更敏感) 梯度爆炸 |
  | smooth L1             |      | L2 适合接近收敛时使用；L1防止梯度爆炸且更鲁棒 | *实现复杂一点*                    |
  
 - **鲁棒性解释** 
      
      > 因为与最小平方相比，最小绝对值偏差方法的鲁棒性更好，因此，它在许多场合都有应用。最小绝对值偏差之所以是鲁棒的，是因为它能处理数据中的异常值。这或许在那些异常值可能被安全地和有效地忽略的研究中很有用。如果需要考虑任一或全部的异常值，那么最小绝对值偏差是更好的选择。

- **稳定性解释**

  > 最小绝对值偏差方法的不稳定性意味着，对于数据集的一个小的水平方向的波动，回归线也许会跳跃很大。在一些数据结构（data configurations）上，该方法有许多连续解；但是，对数据集的一个微小移动，就会跳过某个数据结构在一定区域内的许多连续解。（The method has continuous solutions for some data configurations; however, by moving a datum a small amount, one could “jump past” a configuration which has multiple solutions that span a region. ）在跳过这个区域内的解后，最小绝对值偏差线可能会比之前的线有更大的倾斜。相反地，最小平方法的解是稳定的，因为对于一个数据点的任何微小波动，回归线总是只会发生轻微移动；也就说，回归参数是数据集的连续函数。


## 五、目标检测中的难点
#### 不同size的检测目标

#### 多峰问题（Crowd）

#### 数据长尾分布

## 六、扩展研究方向
- 3D
- Video Object Detection
- multi-task
  - [Segmentation](https://blog.csdn.net/chunfengyanyulove/article/details/83545784)

    > 语义分割（semantic segmentation）：对图像中逐像素进行分类。
    >
    > 实例分割（instance segmentation）：对图像中的object进行检测，并对检测到的object进行分割。
    >
    > 全景分割（panoptic segmentation）：对图像中的所有物体进行描述。

    <img src="img/segmentation.png" width="300px">
- 文本检测（不规则检测框）
- 模型蒸馏