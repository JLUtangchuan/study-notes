{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手写朴素贝叶斯算法\n",
    "\n",
    "#### 参考\n",
    "   - [统计学习方法的代码实现](http://localhost:8888/tree/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/%E7%AC%AC04%E7%AB%A0%20%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF)\n",
    "   - [How To Implement Naive Bayes From Scratch in Python](https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/)\n",
    "   - [朴素贝叶斯的三个常用模型：高斯、多项式、伯努利](https://blog.csdn.net/qq_27009517/article/details/80044431)\n",
    "   \n",
    "\n",
    "#### 算法描述\n",
    "   - 生成模型、概率模型\n",
    "   - 后验概率最大化（判别条件）\n",
    "   - 条件独立性假设\n",
    "   - 概率估计方法（极大似然估计、贝叶斯估计）\n",
    "   \n",
    "#### 编程难点\n",
    "   - 连续值的贝叶斯不好实现\n",
    "   \n",
    "   \n",
    "<br>\n",
    "\n",
    "#### 算法原理\n",
    "  1．朴素贝叶斯法是典型的生成学习方法。生成方法由训练数据学习联合概率分布\n",
    "$P(X,Y)$，然后求得后验概率分布$P(Y|X)$。具体来说，利用训练数据学习$P(X|Y)$和$P(Y)$的估计，得到联合概率分布：\n",
    "\n",
    "$$P(X,Y)＝P(Y)P(X|Y)$$\n",
    "\n",
    "概率估计方法可以是极大似然估计或贝叶斯估计。\n",
    "\n",
    "2．朴素贝叶斯法的基本假设是条件独立性，\n",
    "\n",
    "$$\\begin{aligned} P(X&=x | Y=c_{k} )=P\\left(X^{(1)}=x^{(1)}, \\cdots, X^{(n)}=x^{(n)} | Y=c_{k}\\right) \\\\ &=\\prod_{j=1}^{n} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right) \\end{aligned}$$\n",
    "\n",
    "\n",
    "这是一个较强的假设。由于这一假设，模型包含的条件概率的数量大为减少，朴素贝叶斯法的学习与预测大为简化。因而朴素贝叶斯法高效，且易于实现。其缺点是分类的性能不一定很高。\n",
    "\n",
    "3．朴素贝叶斯法利用贝叶斯定理与学到的联合概率模型进行分类预测。\n",
    "\n",
    "$$P(Y | X)=\\frac{P(X, Y)}{P(X)}=\\frac{P(Y) P(X | Y)}{\\sum_{Y} P(Y) P(X | Y)}$$\n",
    " \n",
    "将输入$x$分到后验概率最大的类$y$。\n",
    "\n",
    "$$y=\\arg \\max _{c_{k}} P\\left(Y=c_{k}\\right) \\prod_{j=1}^{n} P\\left(X_{j}=x^{(j)} | Y=c_{k}\\right)$$\n",
    "\n",
    "后验概率最大等价于0-1损失函数时的期望风险最小化。\n",
    "\n",
    "<br> <br>\n",
    "   \n",
    "#### 实现步骤\n",
    "\n",
    "   - MLE计算$P(X_{k}|Y)$，$P(Y)$.(for each x、y in X,Y)\n",
    "      - 统计Y的类数，每类的个数\n",
    "      - 统计X的每个维度的类以及每个维度某一类在某一种Y下出现的次数\n",
    "   - 计算公式$y=\\arg \\max _{c_{k}} P\\left(Y=c_{k}\\right) \\prod_{j=1}^{n} P\\left(X_{j}=x^{(j)} | Y=c_{k}\\right)$\n",
    "   \n",
    "#### 高斯朴素贝叶斯\n",
    "    为实现连续值的朴素贝叶斯算法，使用高斯朴素贝叶斯，\n",
    "    高斯特征假设这个特征的观测值符合高斯分布\n",
    "    在使用MLE时不再使用计数这种连续值上Work的方法，而是使用高斯分布的模型进行概率估计，\n",
    "    具体的公式为：\n",
    "\n",
    "$$P(x_i | y_k)=\\frac{1}{\\sqrt{2\\pi\\sigma^2_{yk}}}exp(-\\frac{(x_i-\\mu_{yk})^2}{2\\sigma^2_{yk}})$$\n",
    "\n",
    "数学期望(mean)：$\\mu$\n",
    "\n",
    "方差：$\\sigma^2=\\frac{\\sum(X-\\mu)^2}{N}$\n",
    "\n",
    "\n",
    "\n",
    "#### 贝叶斯估计与拉普拉斯平滑\n",
    "\n",
    "    维度增高时，训练样本在输入空间上变得稀疏，某一类的某个属性在训练集中可能缺少一种值，而在实际此类样本中出现了这种值，就需要使用贝叶斯估计。$k=1$时的贝叶斯估计也就是拉普拉斯平滑（也就是分子+1、分母加此属性在训练集的unipue的长度）。\n",
    "\n",
    "\n",
    "#### 其他类型NB\n",
    "   \n",
    "   1.多项式NB：用于文本分类\n",
    "   \n",
    "   2.伯努利NB\n",
    "   \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "#### 朴素贝叶斯的变体（贝叶斯分类器家族）\n",
    "   \n",
    "   1. 半朴素贝叶斯\n",
    "   2. 贝叶斯网"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import math\n",
    "\n",
    "\n",
    "# 数据集导入\n",
    "\n",
    "# sklearn数据分割\n",
    "\n",
    "# 编写NB类\n",
    "class NaiveBayes:\n",
    "    def NaiveBayes(self):\n",
    "        train_x = None\n",
    "        train_y = None\n",
    "        c_y = None\n",
    "        std_x = None\n",
    "        mean_x = None\n",
    "        \n",
    "        p_y = None\n",
    "        num = None\n",
    "        pass\n",
    "    def train(self,x,y):\n",
    "        # 保存数据\n",
    "        self.train_x = np.array(x)\n",
    "        self.train_y = y\n",
    "        self.num = len(y)\n",
    "        # p_y\n",
    "        self.c_y = collections.Counter(y)\n",
    "        # mean_x(y:[])\n",
    "        # 高斯NB 计算每个y下x的均值\n",
    "        def mean_x_fun(i):\n",
    "            flag = np.where(y==i,1,0)\n",
    "            flag = flag[:,np.newaxis]\n",
    "            sumx = np.sum(flag*x,0)\n",
    "            return sumx/self.c_y[i]\n",
    "        meanx = map(lambda i:  mean_x_fun(i) , self.c_y.keys())\n",
    "        self.mean_x = dict(zip(self.c_y.keys(),meanx))\n",
    "        \n",
    "        # std_x\n",
    "        def std_x_fun(i):\n",
    "            flag = np.where(y==i)\n",
    "            \n",
    "            stdx = np.std(x[flag],0) \n",
    "            return stdx\n",
    "        \n",
    "        stdx = map(lambda i:  std_x_fun(i) , self.c_y.keys())\n",
    "        self.std_x = dict(zip(self.c_y.keys(),stdx))\n",
    "        \n",
    "    \n",
    "    def get_norm_pdf(self,x,y):\n",
    "        '''\n",
    "        P(x|y)\n",
    "        返回概率值\n",
    "        '''\n",
    "        P = []\n",
    "        \n",
    "        for i,x_i in enumerate(x):\n",
    "            p = (1/np.sqrt(2*math.pi*(self.std_x[y][i]**2)))*np.exp(-((x_i-self.mean_x[y][i])**2)/(2*(self.std_x[y][i]**2)))\n",
    "            P.append(p)\n",
    "        return P\n",
    "    \n",
    "    def predict_one(self,x):\n",
    "        '''\n",
    "        argmax\n",
    "        '''\n",
    "        P = {}\n",
    "        for y_i in self.c_y.keys():\n",
    "            p = self.c_y[y_i]/self.num\n",
    "            p = p * reduce(lambda i,j : i*j,self.get_norm_pdf(x,y_i))\n",
    "            P[y_i] = p\n",
    "#         print(P)\n",
    "        return max(P,key = P.get)\n",
    "    def predict(self,x):        \n",
    "        n = x.shape[0]\n",
    "        \n",
    "        ans = []\n",
    "        for i in range(n):\n",
    "            ans.append(self.predict_one(x[i,:]))\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始 训练\n",
      "开始预测\n",
      "The accuracy is 96.296296 %\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from sklearn.model_selection import train_test_split\n",
    "url = 'http://archive.ics.uci.edu//ml//machine-learning-databases//wine/wine.data'\n",
    "raw_data = urllib.request.urlopen(url)\n",
    "data = np.loadtxt(raw_data, delimiter=\",\")\n",
    "\n",
    "y = data[:,0]\n",
    "x = data[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.3)\n",
    "\n",
    "\n",
    "print('开始 训练')\n",
    "model = NaiveBayes()\n",
    "model.train(X_train,Y_train)\n",
    "\n",
    "print('开始预测')\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "t = (y_predict[i] == Y_test[i] for i in range(len(y_predict)))\n",
    "\n",
    "acc = sum(list(t))/len(y_predict)\n",
    "# acc\n",
    "\n",
    "\n",
    "print('The accuracy is %f %%' % (100*acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "ch",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "ch",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
